{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDE 3 - Advection-Diffusion\n",
    "\n",
    "\n",
    "#### Problem Setup\n",
    "\n",
    "$f(x,y,t) = au_x + bu_y + cu_{xx} + du_{yy} - u_t$\n",
    "\n",
    "For the generation of our initial data samples we use:\n",
    "\n",
    "$u: \\mathbb{R}^3 \\rightarrow \\mathbb{R}, \\; u(x,y,t) = e^{2x} + 3y - t$ <br>\n",
    "$f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}, \\;f(x,y,t) = 5$ <br>\n",
    "$X_i := (x_i, y_i, t_i) \\in [0,1] \\times [0,1] \\times [0, 0.135] \\subseteq \\mathbb{R}^3$ for $i \\in \\{1, \\dotsc, n\\}$\n",
    "\n",
    "and our known function values will be $\\{u(x_i,y_i), f(x_i,y_i)\\}_{i \\in \\{1, \\dotsc, n\\}}$.\n",
    "\n",
    "We assume that $u$ can be represented as a Gaussian process with SE kernel.\n",
    "\n",
    "$u \\sim \\mathcal{GP}(0, k_{uu}(X_i, X_j; \\theta))$, where $\\theta = \\{\\sigma, l_x, l_y, l_t\\}$.\n",
    "\n",
    "Set the linear operator to:\n",
    "\n",
    "$\\mathcal{L}_X^{\\phi} := a\\partial_x + b\\partial_y + c\\partial_{x,x} + d\\partial_{y,y} - \\partial_t$\n",
    "\n",
    "so that\n",
    "\n",
    "$\\mathcal{L}_X^{\\phi} u = f$\n",
    "\n",
    "Problem at hand: Estimate $\\phi:=\\{a, b\\}$ with $\\{c,d\\} = \\{0.5, 0.5\\}$ fixed (we expect $a = -1, b = 4/3$).\n",
    "\n",
    "\n",
    "#### Step 1: Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import numpy.fft as fft\n",
    "from scipy.linalg import solve_triangular\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables: x, y, t, n, y_u, y_f, s\n",
    "\n",
    "# Number of data samples\n",
    "n = 80\n",
    "\n",
    "# Noise of our data:\n",
    "s = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data():\n",
    "    # np.random.seed(20)\n",
    "    x = np.random.rand(n)\n",
    "    y = np.random.rand(n)\n",
    "    t = np.array([0.015*np.random.randint(10) for i in range(n)])\n",
    "    y_u = np.exp(2*x) + 3*y - t\n",
    "    y_f = 5*np.ones(n)\n",
    "    return (x,y,t,y_u,y_f)\n",
    "(x,y,t,y_u,y_f) = simulate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Evaluate kernels\n",
    "\n",
    "$k_{uu}(X_i, X_j; \\theta) = \\sigma \\cdot exp(-\\frac{1}{2l_x}(x_i-x_j)^2 - \\frac{1}{2l_y}(y_i-y_j)^2 - \\frac{1}{2l_t}(t_i-t_j)^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_i, x_j, y_i, y_j, t_i, t_j, sigma, l_x, l_y, l_t, a,b,c,d = sp.symbols('x_i x_j y_i y_j t_i t_j \\\n",
    "                                                                         sigma l_x l_y l_t a b c d')\n",
    "kuu_sym = sigma*sp.exp(-1/(2*l_x)*((x_i - x_j)**2) - 1/(2*l_y)*((y_i - y_j)**2) \n",
    "                       - 1/(2*l_t)*((t_i - t_j)**2))\n",
    "kuu_fn = sp.lambdify((x_i, x_j, y_i, y_j, t_i, t_j, sigma, l_x, l_y, l_t), kuu_sym, \"numpy\")\n",
    "def kuu(x, y, t, sigma, l_x, l_y, l_t):\n",
    "    k = np.zeros((x.size, x.size))\n",
    "    for i in range(x.size):\n",
    "        for j in range(x.size):\n",
    "            k[i,j] = kuu_fn(x[i], x[j], y[i], y[j], t[i], t[j], sigma, l_x, l_y, l_t)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$k_{ff}(X_i,X_j;\\theta,\\phi)$ <br>\n",
    "$= \\mathcal{L}_{X_i}^{\\phi} \\mathcal{L}_{X_j}^{\\phi} k_{uu}(X_i, X_j; \\theta)$ <br>\n",
    "$= a^2\\partial_{x_i, x_j}k_{uu} + ab \\partial_{x_i, y_j}k_{uu} + ac \\partial_{x_i, x_j, x_j}k_{uu} + ad \\partial_{x_i, y_j, y_j}k_{uu} - a \\partial_{x_i, t_j}k_{uu}$ <br>\n",
    "$+ ba\\partial_{y_i, x_j}k_{uu} + b^2\\partial_{y_i, y_j}k_{uu} + bc\\partial_{y_i, x_j, x_j}k_{uu} + bd\\partial_{y_i, y_j, y_j}k_{uu} - b\\partial_{y_i, t_j}k_{uu}$ <br>\n",
    "$+ ca\\partial_{x_i, x_i, x_j}k_{uu}+ cb\\partial_{x_i, x_i, y_j}k_{uu}+ c^2\\partial_{x_i, x_i, x_j, x_j}k_{uu}+ cd\\partial_{x_i, x_i, y_j, y_j}k_{uu}- c\\partial_{x_i, x_i, t_j}k_{uu}$ <br>\n",
    "$+ da\\partial_{y_i, y_i,x_j}k_{uu}+ db\\partial_{y_i, y_i, y_j}k_{uu}+ dc\\partial_{y_i, y_i, x_j, x_j}k_{uu}+ d^2\\partial_{y_i, y_i, y_j, y_j}k_{uu}- d\\partial_{y_i, y_i, t_j}k_{uu}$ <br>\n",
    "$- a\\partial_{t_i, x_j}k_{uu}- b\\partial_{t_i, y_j}k_{uu}- c\\partial_{t_i, x_j, x_j}k_{uu}- d\\partial_{t_i, y_j, y_j}k_{uu}+ \\partial_{t_i, t_j}k_{uu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kff_sym = a**2*sp.diff(kuu_sym, x_i, x_j) \\\n",
    "        + a*b*sp.diff(kuu_sym, x_i, y_j) \\\n",
    "        + a*c*sp.diff(kuu_sym, x_i, x_j, x_j) \\\n",
    "        + a*d*sp.diff(kuu_sym, x_i, y_j, y_j) \\\n",
    "        - a*sp.diff(kuu_sym, x_i, t_j) \\\n",
    "        + b*a*sp.diff(kuu_sym, y_i, x_j) \\\n",
    "        + b**2*sp.diff(kuu_sym, y_i, y_j) \\\n",
    "        + b*c*sp.diff(kuu_sym, y_i, x_j, x_j) \\\n",
    "        + b*d*sp.diff(kuu_sym, y_i, y_j, y_j) \\\n",
    "        - b*sp.diff(kuu_sym, y_i, t_j) \\\n",
    "        + c*a*sp.diff(kuu_sym, x_i, x_i, x_j) \\\n",
    "        + c*b*sp.diff(kuu_sym, x_i, x_i, y_j) \\\n",
    "        + c**2*sp.diff(kuu_sym, x_i, x_i, x_j, x_j) \\\n",
    "        + c*d*sp.diff(kuu_sym, x_i, x_i, y_j, y_j) \\\n",
    "        - c*sp.diff(kuu_sym, x_i, x_i, t_j) \\\n",
    "        + d*a*sp.diff(kuu_sym, y_i, y_i, x_j) \\\n",
    "        + d*b*sp.diff(kuu_sym, y_i, y_i, y_j) \\\n",
    "        + d*c*sp.diff(kuu_sym, y_i, y_i, x_j, x_j) \\\n",
    "        + d**2*sp.diff(kuu_sym, y_i, y_i, y_j, y_j) \\\n",
    "        - d*sp.diff(kuu_sym, y_i, y_i, t_j) \\\n",
    "        - a*sp.diff(kuu_sym, t_i, x_j) \\\n",
    "        - b*sp.diff(kuu_sym, t_i, y_j) \\\n",
    "        - c*sp.diff(kuu_sym, t_i, x_j, x_j) \\\n",
    "        - d*sp.diff(kuu_sym, t_i, y_j, y_j) \\\n",
    "        + sp.diff(kuu_sym, t_i, t_j)\n",
    "kff_fn = sp.lambdify((x_i, x_j, y_i, y_j, t_i, t_j, sigma, l_x, l_y, l_t, a,b,c,d), kff_sym, \"numpy\")\n",
    "def kff(x, y, t, sigma, l_x, l_y, l_t, a,b,c,d):\n",
    "    k = np.zeros((x.size, x.size))\n",
    "    for i in range(x.size):\n",
    "        for j in range(x.size):\n",
    "            k[i,j] = kff_fn(x[i], x[j], y[i], y[j], t[i], t[j], sigma, l_x, l_y, l_t, a,b,c,d)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$k_{fu}(X_i,X_j;\\theta,\\phi) \\\\\n",
    "= \\mathcal{L}_{X_i}^{\\phi} k_{uu}(X_i, X_j; \\theta) \\\\\n",
    "= a\\partial_{x_i}k_{uu} + b \\partial_{y_i}k_{uu} + c \\partial_{x_i, x_i}k_{uu} + d \\partial_{y_i, y_i}k_{uu} -  \\partial_{t_i}k_{uu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfu_sym = a*sp.diff(kuu_sym, x_i) \\\n",
    "        + b*sp.diff(kuu_sym, y_i) \\\n",
    "        + c*sp.diff(kuu_sym, x_i, x_i) \\\n",
    "        + d*sp.diff(kuu_sym, y_i, y_i) \\\n",
    "        - sp.diff(kuu_sym, t_i)\n",
    "kfu_fn = sp.lambdify((x_i, x_j, y_i, y_j, t_i, t_j, sigma, l_x, l_y, l_t, a,b,c,d), kfu_sym, \"numpy\")\n",
    "def kfu(x, y, t, sigma, l_x, l_y, l_t, a,b,c,d):\n",
    "    k = np.zeros((x.size, x.size))\n",
    "    for i in range(x.size):\n",
    "        for j in range(x.size):\n",
    "            k[i,j] = kfu_fn(x[i], x[j], y[i], y[j], t[i], t[j], sigma, l_x, l_y, l_t, a,b,c,d)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kuf(x, y, t, sigma, l_x, l_y, l_t, a,b,c,d):\n",
    "    return kfu(x, y, t, sigma, l_x, l_y, l_t, a,b,c,d).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Compute NLML (with Cholesky decomposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the covariance matrix K and its inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(sigma, l_x, l_y, l_t, a,b,c,d, s):\n",
    "    K_mat = np.block([\n",
    "        [kuu(x, y, t, sigma, l_x, l_y, l_t)+s*np.eye(n),kuf(x, y, t, sigma, l_x, l_y, l_t, a,b,c,d)],\n",
    "        [kfu(x, y, t, sigma, l_x, l_y, l_t,a,b,c,d),kff(x,y,t,sigma,l_x,l_y,l_t,a,b,c,d)+s*np.eye(n)]\n",
    "    ])\n",
    "    return K_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_inv_and_det(sigma, l_x, l_y, l_t, a,b,c,d, s):\n",
    "    \n",
    "    K_inv = np.zeros((2*n, 2*n))\n",
    "    log_sum = 0\n",
    "    \n",
    "    # Use Cholesky, if possible. Otherwise use SVD.\n",
    "        \n",
    "    try:\n",
    "        L = np.linalg.cholesky(K(sigma, l_x, l_y, l_t, a,b,c,d, s))\n",
    "        L_inv = solve_triangular(L, np.identity(2*n), lower=True) # Slight performance boost \n",
    "                                                                  # over np.linalg.inv\n",
    "        K_inv = (L_inv.T).dot(L_inv)\n",
    "\n",
    "        for i in range(2*n):\n",
    "            log_sum = log_sum + np.log(np.abs(L[i,i]))\n",
    "    except np.linalg.LinAlgError:\n",
    "        # Inverse of K via SVD\n",
    "        u, s_mat, vt = np.linalg.svd(K(sigma, l_x, l_y, l_t, a,b,c,d, s))\n",
    "        K_inv = (vt.T).dot(np.linalg.inv(np.diag(s_mat))).dot(u.T)  \n",
    "\n",
    "        # Calculating the log of the determinant of K\n",
    "        # Singular values are always positive.\n",
    "        for i in range(s_mat.size):\n",
    "            log_sum = log_sum + np.log(s_mat[i])\n",
    "        \n",
    "    return K_inv, log_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing normalized negative log-likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlml(params):\n",
    "    \n",
    "    c_par = 0.5\n",
    "    d_par = 0.5\n",
    "    \n",
    "    # Exponentiation to enable unconstrained optimization\n",
    "    sigma_exp = np.exp(params[0]) \n",
    "    l_x_exp = np.exp(params[1])\n",
    "    l_y_exp = np.exp(params[2]) \n",
    "    l_t_exp = np.exp(params[3])\n",
    "    # a = params[4]\n",
    "    y_con = np.concatenate((y_u, y_f))\n",
    "    \n",
    "    A,b = K_inv_and_det(sigma_exp, l_x_exp, l_y_exp, l_t_exp, params[4],params[5],c_par,d_par, s)\n",
    "        \n",
    "    val = b + y_con @ A @ y_con\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Nelder-Mead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbackf(params):\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_restarts(x,y,y_u,y_f,n=5): \n",
    "    all_results = []\n",
    "    for it in range(0,n):\n",
    "        all_results.append(opt.minimize(nlml, np.random.rand(6), callback = callbackf, \n",
    "                                        method=\"Nelder-Mead\", \n",
    "                                        options={'maxfev':10000, 'fatol': 0.001}))\n",
    "    return min(all_results, key = lambda x: x.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "m = minimize_restarts(x, y, y_u, y_f, 3)\n",
    "t_Nelder = time.time() - t0\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10960.663992643356"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_Nelder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inferred parameters are:\n",
      "a =  -0.9999297756402357\n",
      "b =  1.333116719690449\n"
     ]
    }
   ],
   "source": [
    "print('The inferred parameters are:')\n",
    "print('a = ', m.x[4])\n",
    "print('b = ', m.x[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
